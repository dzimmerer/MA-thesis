\chapter{Experiments\&Results}

\section{Datasets}

We evaluate our models on three different datasets.
The dataset size is primarily limited by the computational resources, such as memory and computation time. 

\subsection{Stripe Dataset}

We generate a $10 \times 10$ pixel noisy stripe dataset, with three different oriented stripes, horizontal, diagonal, vertical. 
This could represent an object similar to a pen recorded with a event-based camera, and result in an grasp id.
In the easiest version of this dataset, the stripes always occur on the same places, with some random noise (see Fig. \ref{fig:stripes1}).
An more complex version of the datasets contains the stripes randomly distributed across the whole image(see Fig. \ref{fig:stripes2}).
The dataset can be either binary or continuous(see Fig. \ref{fig:stripes3} \& \ref{fig:stripes4}).


\begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{.49\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/stripes1.png}
  		\caption{Samples from the unshifted binary stripe dataset.}
  		\label{fig:stripes1}
	\end{subfigure}%
	\begin{subfigure}[t]{.49\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/stripes2.png}
  		\caption{Samples from the  shifted binary stripe dataset.}
  		\label{fig:stripes2}
	\end{subfigure}
	\begin{subfigure}[t]{.49\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/stripes3.png}
  		\caption{Samples from the unshifted continuous stripe dataset.}
  		\label{fig:stripes3}
	\end{subfigure}
	\begin{subfigure}[t]{.49\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/stripes4.png}
  		\caption{Samples from the shifted continuous stripe dataset.}
  		\label{fig:stripes4}
	\end{subfigure}
	\caption{Samples from the stripe dataset. }
	\label{fig:stripes}
\end{figure}


\subsection{MNIST}

We also evaluate the models on the MNIST dataset \cite{lecun-mnisthandwrittendigit-2010}. 
The MNIST dataset consists of 60000 28x28 pixel gray images of handwritten numbers 0-9.
Samples of the dataset are given in Figure \ref{fig:mnist}.

\begin{figure}[h!]
	\centering
    	\includegraphics[width=0.6\textwidth]{imgs/mnist.png} 
    \caption{Samples from the MNIST dataset.}
	\label{fig:mnist}
\end{figure}


\subsection{Poker-DVS}

Another dataset used in this thesis is the Poker DVS dataset \cite{serrano2013128}.
The Dataset consists of 131 poker pip symbols extracted from 3 separate DVS recordings, while quickly browsing poker cards.
From the $128 \times 128$ recorded image, a $32 \times 32$ pixel patch, containing the symbol is extracted.
As a compromise between computational and classification performance, we down sample the patches to a size of $16 \times 16$ pixels and only consider spikes in the first $8000 \mu s$, due to the constricted learning time per sample.
The resulting dataset is visualized as a accumulation over time in Figure \ref{fig:pokerdvs}.
 
    
\begin{figure}[h!]
	\centering
    	\includegraphics[width=0.6\textwidth]{imgs/poker_ds.png} 
    \caption{Visualization of samples from the Poker-DVS dataset.}
	\label{fig:pokerdvs}
\end{figure}


\section{Experiments}

We orient our experiments primarily on the stripe dataset, due to time and computational constrains which will be explained at first.
After evaluating our models on the stripe dataset, we look on the performance on other datasets for comparison and generalization.     

\subsection{Computational Constrains}

Most of the experiments were executed on a quad-core processor with 3.2 GHz, 16 GB RAM and a NVidia GTX 650.

In the analog case CNNs can be optimized to utilize the standard processing pipeline in most computers. 
Due to the shared weights, only one copy of each convolutional filter has to be stored. 
In Addition each feature map has to be calculated and stored as well.
Calculating a features map can be reduced to a convolution operation over the previous feature maps with a kernel, which can be implemented quite computational efficient.
Thus the data needed for a analog CNN is given by the size of the feature maps and the kernel matrices, the operations can be primarily reduced to convolutions.  

In contrast to CNNs, spiking networks with a convolutional structure, can not utilize all of the benefits.
While the shared weights still reduce the number of learning steps needed, compared to a network without shared weights, the structure is more complicated.
Due to the time dependent nature of the synapses and neurons, each single neuron and synapse has to explicitly modelled.
While the number of neurons is equivalent to the number of elements in a feature map and thus comparable to the units in a classical CNN, synapses with shared weights cannot be reduced to a single synapse as in kernel matrices.
In addition to the additional computations needed for the neuron dynamics, these synapse dynamics, which do not have to be modelled in classical CNNs, can drastically increase the computational complexity.   

For example a CNN over $5 \times 5 = 25$ dimensional input data with a $4 \times 4 = 16$ kernel, would result in a $2 \times 2 = 4$ feature map, so the number of stored vales is $45$. 
For a spiking network, in addition to modelling the $25$ input data and the $4$ feature map as time dynamic neurons, now $(2 \times 2) \times (4 \times 4) = 64$ synapses and their dynamics have to be modelled.
This number increases quadratically as the filter size is reduced or the number of filters is increased.

Due to these constrains, the experiments primarily focus on smaller datasets and are not performed on current state-of-the-art image recognition datasets. 
Specialized neuromorphic hardware could speed up the computations and allow the evaluation of more complex datasets.  

\subsection{Conversion}

At first we compare the three different converted DBNs.
Therefore a analogue DBN was trained on the MINST dataset.
The dataset was split into 50.000 training images and 10.000 images for testing.
The DBN consists of three RBMs (similar to Fig. \ref{fig:dbnmnist}), where the first RBM is convolutional with 20 $1 \times 16 \times 16$ filters. 
The second RBM has 15 $20 \times 10 \times 10$ filters. 
The third RBM , which can also be seen as the association layer of the DBN, is fully connected and uses the output of the second RBM as well as the labels as input data.  
Each RBM is trained for $5$ epochs with CD-$2$ over the whole dataset with a learning rate of $0.1$ and a weight decay of $0.0003$.

The resulting features of the first layer are visualized in Fig \ref{fig:rbmw}.

\begin{figure}
	\centering
    	\includegraphics[width=0.7\textwidth]{imgs/weights_rbm.png} 
    \caption{Visualized filters $16 \times 16$ filters of the first layer convolutional RBM of a DBN trained on MNIST.}
	\label{fig:rbmw}
\end{figure}

In the end the DBN reaches a classification performance of $82.45$ \%. 
This could be further improved by increasing the training time, fine-tuning the structure and parameters of the training algorithm of the DBN, which was not the focus point of this thesis.
An intentionally simple DBN structure was chosen due to the computational effort necessary to simulate the DBN as a spiking neural network. 


\subsubsection{Conversion comparison}

For the comparison of the conversion methods, we convert the RBM to its spiking counter parts, as described in 5.2 . 
The input rate of the images are converted to Poisson spike-trains, with a maximal frequency of $\lambda = 100 \text{Hz}$ .
Each input sample is simulated for $500 \text{ms}$, but we'll inspect how the simulated timespan effects the output.
Since the simulation time of one sample can take more the 1 minute, we evaluate all approaches on the same randomly drawn subset of the test set consisting of $100$ samples.

A visual inspection of the activations can be seen in Fig \ref{fig:convacts}. 
It is quite apparent, that all approaches capture the basic activation characteristics. 
While the conversion as a DBN is able to simulate the activation probabilities more closely to the original DBN, the spiking CNN show similar performance by a more deterministic behaviour replicating only the essential activation structure.
To quantify those differences we calculate the Kullback-Leibler divergence between the activation, which indicates the similarity of two distributions (the lower the value, the more similar are the distributions), as seen in Table \ref{tab:kldiv}.

%TODO different sorting (layer wise)


\begin{table}[]
\centering
\caption{Kullback-Leibler divergence between the activations in the feature maps.}
\label{tab:kldiv}
\begin{tabular}{|l|l|l|l|}
\hline
Layer & CNN   & COBA LIF DBN & CUBA LIF DBN \\ \hline
1     & 0.014 & 0.014        & 0.014        \\
2     & 0.925 & 0.072        & 0.069        \\
3     & 0.260 & 0.170        & 0.248        \\
4     & 0.296 & 2.61         & 1.067        \\
5     & 0.624 & 1.254        & 0.445        \\ \hline
\end{tabular}
\end{table}


\begin{table}[]
\centering
\caption{Classification performances of the converted spiking DBNs to a the analog DBN on a subset of 100 samples.}
\label{tab:convperf}
\begin{tabular}{|l|l|l|}
\hline
	 				& Classification Accuracy    & Average runtime per sample \\ \hline
DBN     			& 0.87 & 0.5 s               \\
Spiking CNN     	& 0.83 & 24.2 s                \\
COBA LIF DBN     	& 0.92 & 141.3 s                \\
CUBA LIF DBN     	& 0.93 & 30.6 s                 \\\hline
\end{tabular}
\end{table}


\begin{figure}
	\centering
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/rbm00000.png}
  		\caption{Input data.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/cnn00000.png}
  		\caption{Spike input.}
  		\label{fig:sub2}
	\end{subfigure}
	
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/rbm00001.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/cnn00001.png}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/coba00001.png}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/cuba00001.png}
  		\label{fig:sub2}
	\end{subfigure}	

	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/rbm00002.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/cnn00002.png}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/coba00002.png}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/cuba00002.png}
  		\label{fig:sub2}
	\end{subfigure}	

	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/rbm00003.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/cnn00003.png}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/coba00003.png}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/cuba00003.png}
  		\label{fig:sub2}
	\end{subfigure}	
	
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/rbm00004.png}
  		\caption{RBM.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/cnn00004.png}
  		\caption{CNN.}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/coba00004.png}
  		\caption{COBA LIF DBN.}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.24\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/convert/cuba00004.png}
  		\caption{CUBA LIF DBN.}
  		\label{fig:sub2}
	\end{subfigure}	
	\caption{Activations in the features maps in a classical convolutional RBM. }
	\label{fig:convacts}
\end{figure}


\begin{figure}[h!]
	\centering
	\begin{subfigure}{.24\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/convert/err/err1.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.24\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/convert/err/err2.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.24\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/convert/err/err4.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.24\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/convert/err/err3.png}
  		\label{fig:sub1}
	\end{subfigure}%
	
	
	\caption{Misclassifications of the spiking DBNs. Often $9$ and $4$ are mixed up. The first three are classified as a $9$, the fourth one is classified as a $4$. The images all share a lot of features with the suggested class and the correct class was always the second most probable.}
	\label{fig:mismnisthum}
\end{figure}


%
%\begin{figure}
%	\centering
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/rbm00000.png}
%  		\caption{Input data.}
%  		\label{fig:sub1}
%	\end{subfigure}%
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/rbm00001.png}
%  		\caption{Activations in the features maps of the first RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/rbm00002.png}
%  		\caption{Activations in the features maps of the second RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/rbm00003.png}
%  		\caption{Activations in the features maps of the third RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}	
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/rbm00004.png}
%  		\caption{Activations in the features maps of the fourth/label layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\caption{Activations in the features maps in a classical convolutional RBM. }
%	\label{fig:stripes}
%\end{figure}
%
%\begin{figure}
%	\centering
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/cnn00000.png}
%  		\caption{Input data.}
%  		\label{fig:sub1}
%	\end{subfigure}%
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/cnn00001.png}
%  		\caption{Activations in the features maps of the first RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/cnn00002.png}
%  		\caption{Activations in the features maps of the second RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/cnn00003.png}
%  		\caption{Activations in the features maps of the third RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}	
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/cnn00004.png}
%  		\caption{Activations in the features maps of the fourth/label layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\caption{Activations in the features maps in the as CNN converted RBM. }
%	\label{fig:stripes}
%\end{figure}
%
%\begin{figure}
%	\centering
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/coba00000.png}
%  		\caption{Input data.}
%  		\label{fig:sub1}
%	\end{subfigure}%
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/coba00001.png}
%  		\caption{Activations in the features maps of the first RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/coba00002.png}
%  		\caption{Activations in the features maps of the second RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/coba00003.png}
%  		\caption{Activations in the features maps of the third RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}	
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/coba00004.png}
%  		\caption{Activations in the features maps of the fourth/label layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\caption{Activations in the features maps in a as DBN converted RBM with conductance based LIF neurons. }
%	\label{fig:stripes}
%\end{figure}
%
%\begin{figure}
%	\centering
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/cuba00000.png}
%  		\caption{Input data.}
%  		\label{fig:sub1}
%	\end{subfigure}%
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/cuba00001.png}
%  		\caption{Activations in the features maps of the first RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/cuba00002.png}
%  		\caption{Activations in the features maps of the second RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/cuba00003.png}
%  		\caption{Activations in the features maps of the third RBM layer.}
%  		\label{fig:sub2}
%	\end{subfigure}	
%	\begin{subfigure}[t]{.32\textwidth}
%  		\centering
%  		\includegraphics[width=.9\linewidth]{imgs/convert/cuba00004.png}
%  		\caption{Activations in the features maps of the fourth/label layer.}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\caption{Activations in the features maps in a as DBN converted RBM with current based LIF neurons. }
%	\label{fig:stripes}
%\end{figure}

The performance on the partial dataset can be seen in Table \ref{tab:convperf}.
It is apparent, that all show similar performance. Interestingly the spiking DBN sometimes shows better performance than the RBM.
Most misclassifications can be from a human perspective been categorized as "reasonable" mistakes (as seen in Fig. \ref{fig:mismnisthum}) and hint, that further fine-tuning the DBN could resolve some misclassifications.

Another factor is the simulated runtime for each sample. It is quite apparent from Table \ref{tab:pervovert}, that a longer classification time benefits the performance.


\begin{table}[]
\centering
\caption{Classification performances of the converted spiking DBNs with different simulated runtimes.}
\label{tab:pervovert}
\begin{tabular}{|l|l|l|l|l|}
\hline
	 				& \multicolumn{2}{|l|}{CNN}   & \multicolumn{2}{|l|}{CUBA LIF DBN} \\ \hline
Simulated time		 				& Classification Accuracy    & Execution time & Classification Accuracy    & runtime \\ \hline
50 ms    	& 0.69 & 7.8 s 		& 0.81 & 8.1 s               \\
100 ms     	& 0.77 & 9.2 s  	& 0.89 & 10.5 s              \\
200 ms    	& 0.76 & 13.1 s   & 0.89 & 14.6 s             \\
300 ms    	& 0.75 & 15.1 s   & 0.91 & 18.5 s             \\
500 ms     	& 0.83 & 24.2 s    & 0.93 & 30.6 s             \\\hline
\end{tabular}
\end{table}

\subsection{eCD}

To get an intuitive insight into the eCD algorithm, we visualize the positive and negative phase for the stripe dataset.
It is apparent, that in the positive phase a sample from the data distribution is learned and in the negative phase the model distribution is unlearned (see Fig. \ref{fig:ecdstrlearn}).
As the training progresses and the model distribution approximates the data distribution more closely the weight updates become smaller (see Fig. \ref{fig:ecdwdiff}). 
The eCD-parameters chosen for our experiments are given in Table \ref{tab:ecdrunparam}.

\begin{table}[]
\caption{eCD-parameters for the experiments}
\centering
\label{tab:ecdrunparam}
\begin{tabular}{|ll|}
\hline
$t_{burn-in}$    	& 14 ms 		    \\
$t_{learn}$    		& 56 ms 		     \\
$t_{flush}$    		& 28 ms		             \\
Learn-rate     		& 1.0 		                 \\
Weight-decay    	& 0.001		              \\
Weight synchronization after $n$ samples     	& 1		              \\\hline
\end{tabular}
\end{table}


\begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{.19\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/inspect/00010.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.19\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/inspect/00011.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.19\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/inspect/00012.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.19\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/inspect/00013.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.19\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/inspect/00014.png}
  		\label{fig:sub1}
	\end{subfigure}%
	
	\begin{subfigure}[t]{.19\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/inspect/00015.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.19\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/inspect/00016.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.19\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/inspect/00017.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.19\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/inspect/00018.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\caption{Positive phase and negative phase of a diagonal stripe with 4 filters. In the first 4 images the stripe is learned, while during the last 4 images the model distribution is unlearned.}
	\label{fig:ecdstrlearn}
\end{figure}

\begin{figure}
	\centering
    	\includegraphics[width=0.5\textwidth]{imgs/inspect/wdiff.png} 
    \caption{Accumulated weight change for each training sample. As more samples are presented and the weights specialize, the total weight updates decrease.}
	\label{fig:ecdwdiff}
\end{figure}



\subsubsection{Learning the data distribution}

To evaluate how good the model distribution matches the data distribution, we compare the input sample to the reconstruction obtained after the removing the input and letting the system settle towards it's model distribution.
This is visualized in Figure \ref{fig:posnegstrec} and \ref{fig:actdevstr}.
In the beginning of the training the model distribution and thus the reconstruction is approximately random.
As the training progresses, the reconstruction matches the original input image more closely and thus the model distribution shifts towards the data distribution.

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/reconst/00001.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/reconst/00003.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/reconst/00005.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/reconst/00007.png}
  		\label{fig:sub1}
	\end{subfigure}%
	
	
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/reconst/00002.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/reconst/00004.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/reconst/00006.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/reconst/00008.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\caption{Positive phase and negative phase of a diagonal stripe with 4 filters. In the first 4 images the stripe is learned, while during the last 4 images the model distribution is unlearned.}
	\label{fig:posnegstrec}
\end{figure}

In Addition the weights/ filters become more specialized, thus resulting in a sparse activation of the hidden layer as shown in Figure \ref{fig:actdevstr}.  
\\\\\\\\
\begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/reconst/00030_h.png}
  		\caption{Activations at the beginning.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/reconst/00975_h.png}
  		\caption{Activations after some training.}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/reconst/hact.png}
  		\caption{Total number of activations per sample over time.}
  		\label{fig:sub2}
	\end{subfigure}
	\caption{Activations in the features maps in a as DBN converted RBM with current based LIF neurons. }
	\label{fig:actdevstr}
\end{figure}


\subsubsection{Lateral connections}

An important addition to the convolution spiking RBM, are the lateral inhibitory connections in the hidden layer. 
Each neuron in the hidden layer at position $i,j$ in feature map $k$ is connected to other neurons in all other feature maps $K \ k$ at the approximately same position $i', j'$ with $ |i'-i| \le 2 , |j' - j| \le 2 $.   
This results in faster training and more discriminative features and better results (see Fig. \ref{fig:latconstr} for the learned weights of both approaches).

\begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/inhib/02129.png}
  		\caption{Weights without lateral inhibitory connections.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/inhib/03023.png}
  		\caption{Weights with lateral inhibitory connections.}
  		\label{fig:sub2}
	\end{subfigure}
	\caption{$5 \times 5$ convolution filter matrices with and without lateral inhibitory connections in the top RBM layer on the stripe dataset. Whereas the filters without lateral connections look more similar the filters with lateral connections are more different and discriminative.}
	\label{fig:latconstr}
\end{figure}

\subsubsection{Convolution vs no Convolution}

To demonstrate the benefits of convolution even on a small dataset we train two DBNs with the same number of free parameters, one convolutional , one without any convolution.
The parameters for the first layer are chosen to be $20$ and for the second "association" layer $250$.

For the convolution DBN this results in a structure of $3$ $7x7$ convolutional filters in the first layer, and a fully connected RBM with $5$ hidden units in the second layer.
For the DBN without convolution, this results in two fully connected RBMs, where the first RBM has $2$ hidden units and the second RBM has $120$ hidden units.

Both DBNs are trained with 100 samples for the first layer and 500 samples with labels for the second layer, since it has more free parameters.

The resulting weights are visualized in Fig. \ref{fig:wwoconwconv}.

\begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/cvsnc/wc.png}
  		\caption{Weights of the DBN with convolutions.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/cvsnc/wnc.png}
  		\caption{Weights of the DBN without convolutions.}
  		\label{fig:sub2}
	\end{subfigure}
	\caption{Weight of the first layers of the DBNs with and without convolutions.}
	\label{fig:wwoconwconv}
\end{figure}


This suggests, that the DBN with convolution is able to capture the structure of the data better with the same number of free parameters. 
This is also apparent in the final classification results.
While the DBN without convolutions reaches its top performance of $60 \%$ after 500 samples, the convolutional DBN reaches its top performance of $100 \%$ already after being presented with 300 samples.
 

\subsubsection{Simulation time}

We also evaluate how the simulation time for one time step changes as the network complexity increases.
A network on the $10 \times 10$ pixel stripe dataset is run for 1 learning step and the time is measured.
As we increase the number of hidden units, the runtime increases more or less linearly (see Fig \ref{fig:simtime}).

\begin{figure}[h!]
	\centering
    	\includegraphics[width=0.65\textwidth]{imgs/runtime-1.png} 
    \caption{The runtime of a learning step in dependence on the size of the Network.}
	\label{fig:simtime}
\end{figure}


\subsubsection{Performance on the stripe dataset}

Due to the training time, we train the a DBN on the stripe dataset. 
The DBN consists of two layers, with the first layer consisting of a convolutional RBM with $20$ $7 \times 7$ filters and the second layer being fully connected with $20$ hidden units (see Fig \ref{fig:dbnstrarch} for the abstract architecture).
The first layer is trained with $1000$ samples without labels.
The weights of the first layer are then keep fixed and the second layer is trained over $500$ samples with their corresponding labels.
The development of the of the weights in the first layer can be seen in Figure \ref{fig:stripesdbnw}.

\begin{figure}[h!]
	\centering
    	\includegraphics[width=0.7\textwidth]{imgs/dbn_stripe.png} 
    \caption{Abstract architecture of the DBN for the stripe dataset.}
	\label{fig:dbnstrarch}
\end{figure}


\begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/w1.png}
  		\caption{Weights a the beginning of training.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/w2.png}
  		\caption{Weights after 250 samples.}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/w3.png}
  		\caption{Weights after 500 samples.}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/w4.png}
  		\caption{Weights after 750 samples.}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/w5.png}
  		\caption{Weights after 1000 samples.}
  		\label{fig:sub2}
	\end{subfigure}
	\caption{$5 \times 5$ convolution filter matrices development during training with $1000$ samples.}
	\label{fig:stripesdbnw}
\end{figure}



\begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/00006_v.png}
  		\caption{Visible layer activations in the beginning.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/01992_v.png}
  		\caption{Visible layer  activations after 1000 samples.}
  		\label{fig:sub2}
	\end{subfigure}
	
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/00006_h.png}
  		\caption{Hidden layer activations in the beginning.}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/01992_h.png}
  		\caption{Hidden layer  activations after 1000 samples.}
  		\label{fig:sub2}
	\end{subfigure}
	\caption{Activations/ spikes in the layers of the first RBM during training. As the training progresses, the activations become more sparse. The hidden layer learns new representations for the data. The model distribution approximates the data distribution, resulting in a nearly perfect reconstruction of the input data.}
	\label{fig:stripesspl1}
\end{figure}



\begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/20076_v.png}
  		\caption{Visible layer activations in the beginning.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/20946_v.png}
  		\caption{Visible layer  activations after 500 samples.}
  		\label{fig:sub2}
	\end{subfigure}
	
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/20076_c.png}
  		\caption{Label layer activations in the beginning.}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/20946_c.png}
  		\caption{Label layer activations after 500 samples.}
  		\label{fig:sub2}
	\end{subfigure}
	
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/20076_h.png}
  		\caption{Hidden layer activations in the beginning.}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.32\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/7x7/20946_h.png}
  		\caption{Hidden layer  activations after 500 samples.}
  		\label{fig:sub2}
	\end{subfigure}
	\caption{Activations/ spikes in the layers of the second RBM during training. As the training progresses, the activations become more sparse. The hidden layer learns new 20 dimensional representations for the data. The model distribution approximates the data distribution, resulting in a nearly perfect reconstruction of the input data, especially of the label.}
	\label{fig:stripesspl2}
\end{figure}

Another indicator of the training progress is given by the spikes as seen in Figure \ref{fig:stripesspl1} \& \ref{fig:stripesspl2}.
The resulting spiking DBN show shows a performance of $100 \%$ classification accuracy on the test set. 


\subsubsection{Performance on the Poker-DVS dataset}

For the Poker-DVS dataset, a DBN with two layers, a convolutional and an association layer, is used.
The convolutional RBM is defined by $10$ $14 \times 14$ convolution filters.
The association RBM layer has 10 hidden units (see Fig. \ref{fig:pokerdbnarch} for the architecture).
Each layer is trained with $200$ samples drawn randomly from the training set.
The resulting filters can be seen in Fig \ref{fig:pokerw}.
To evaluate the extracted features, we show a reconstruction and completion of the input data (see Fig \ref{fig:pokerrecon} \& \ref{fig:pokercompl}) and the classification performance. 
The trained DBN reaches a peak performance of $90 \%$ on the training set (see Fig \ref{fig:poker_err}).


\begin{figure}[h!]
	\centering
    	\includegraphics[width=0.7\textwidth]{imgs/poker/dbn_poker.png} 
    \caption{Abstract architecture of the DBN for the poker dataset.}
	\label{fig:pokerdbnarch}
\end{figure}

\begin{figure}[h!]
	\centering
    	\includegraphics[width=0.7\textwidth]{imgs/poker/w2.png} 
    \caption{Visualization of the convolution filters of the first layer RBM.}
	\label{fig:pokerw}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/poker/acc.png}
  		\caption{Accuracy of the DBN during training with 200 samples.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/poker/recon_err.png}
  		\caption{Reconstruction error of the first layer of the DBN during training with 200 samples.}
  		\label{fig:sub2}
	\end{subfigure}
	\caption{The accuracy and reconstruction error of the DBN. The accuracy increases to a maximal value of $90 \%$ and the reconstruction error decreases, indicating discriminative features. }
	\label{fig:poker_err}
\end{figure}


\begin{figure}[h!]
	\centering
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/recon_img1.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/recon_img3.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/recon_img5.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/recon_img7.png}
  		\label{fig:sub1}
	\end{subfigure}%
	
	
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/recon_img2.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/recon_img4.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/recon_img6.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/recon_img8.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\caption{Positive phase and negative phase in the first layer of the DBN of after training on the Poker-DVS dataset. The reconstruction of each class is nearly perfect indicating, the DBN has learned the basic structure of the data.}
	\label{fig:pokerrecon}
\end{figure}



\begin{figure}[h!]
	\centering
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/compl11.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/compl21.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/compl31.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/compl41.png}
  		\label{fig:sub1}
	\end{subfigure}%
	
	
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/compl12.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/compl22.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/compl32.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
  		\centering
  		\includegraphics[width=\linewidth]{imgs/poker/compl42.png}
  		\label{fig:sub1}
	\end{subfigure}%
	\caption{Completion of partially fed input data. In the first two columns the bottom $4$ rows and in the last two columns the $7$ bottom rows in the image data were omitted. After training, the DBN was able to reconstruct some of the missing input data an complete the input data.}
	\label{fig:pokercompl}
\end{figure}


\subsection{Conversion vs online}

At last we compare the converted DBN with a directly trained spiking DBN.

\subsubsection{Direct comparison}

We train an analog DBN and a spiking DBN with the same architecture and number of samples and compare their performance.

We choose a simple structure with $3$ convolutional filters of size $7 \times 7$ for the first layer RBM and for the second RBM we use a fully connected RBM with $5$ hidden variables.
The first layer of the DBN is trained unsupervised on $100$ samples from the stripe dataset and the second layer is trained on $500$ data samples with their labels from the stripe dataset.
The analog RBM is trained with a batch size of one to get a similar learning behaviour as the spiking DBN. 
The learning rates are chose to show similar weight alterations in each step and to show best classification performance after being presented with 500 data samples.

The resulting convolutional filters are visualized in Fig \ref{fig:convvsnoconv}. 

 \begin{figure}[h!]
	\centering
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/vs/w_rbm.png}
  		\caption{Weights of the analog DBN.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.45\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/vs/w_spike.png}
  		\caption{Weights of the spinking DBN.}
  		\label{fig:sub2}
	\end{subfigure}
	\caption{Convolutional filters of the first layers of the analog and spiking convolutional DBNs after 100 training samples. The weights of the spiking DBN appear to be more discriminative.}
	\label{fig:convvsnoconv}
\end{figure}

It is apparent, that the weights of the first layer in the spiking DBN are more discriminative compared to the analog DBN.
This also show in the classification performance, where the analog DBN only reaches $67 \%$ and the spiking DBN reaches $100 \%$.

