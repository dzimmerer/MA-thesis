\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{lecun-mnisthandwrittendigit-2010}
\citation{lecun-mnisthandwrittendigit-2010}
\citation{lecun-mnisthandwrittendigit-2010}
\citation{serrano2013128}
\citation{serrano2013128}
\citation{serrano2013128}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Experiments \& Results}{57}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c:expres}{{6}{57}{Experiments \& Results}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Datasets}{57}{section.6.1}}
\newlabel{c:datasets}{{6.1}{57}{Datasets}{section.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Stripe Dataset}{57}{subsection.6.1.1}}
\newlabel{c:stripes}{{6.1.1}{57}{Stripe Dataset}{subsection.6.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}MNIST}{57}{subsection.6.1.2}}
\newlabel{c:mnist}{{6.1.2}{57}{MNIST}{subsection.6.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}Poker-DVS}{57}{subsection.6.1.3}}
\newlabel{c:pokerdvs}{{6.1.3}{57}{Poker-DVS}{subsection.6.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Experiments}{57}{section.6.2}}
\newlabel{c:exps}{{6.2}{57}{Experiments}{section.6.2}{}}
\newlabel{fig:stripes1}{{6.1a}{58}{\relax }{figure.caption.95}{}}
\newlabel{sub@fig:stripes1}{{a}{58}{\relax }{figure.caption.95}{}}
\newlabel{fig:stripes2}{{6.1b}{58}{\relax }{figure.caption.95}{}}
\newlabel{sub@fig:stripes2}{{b}{58}{\relax }{figure.caption.95}{}}
\newlabel{fig:stripes3}{{6.1c}{58}{\relax }{figure.caption.95}{}}
\newlabel{sub@fig:stripes3}{{c}{58}{\relax }{figure.caption.95}{}}
\newlabel{fig:stripes4}{{6.1d}{58}{\relax }{figure.caption.95}{}}
\newlabel{sub@fig:stripes4}{{d}{58}{\relax }{figure.caption.95}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Samples from the $10 \times 10$ pixel stripe dataset. The stripes in (a) and (c) have the same position in the image, while the stripes in (b) and (d) can appear anywhere in the image. In (a) and (b) the images are binary , i.e a pixel value $p \in \{0,1\}$, while in (c) and (d) the values are continuous i.e $p \in [0,1 ]$. \relax }}{58}{figure.caption.95}}
\newlabel{fig:stripes}{{6.1}{58}{Samples from the $10 \times 10$ pixel stripe dataset. The stripes in (a) and (c) have the same position in the image, while the stripes in (b) and (d) can appear anywhere in the image. In (a) and (b) the images are binary , i.e a pixel value $p \in \{0,1\}$, while in (c) and (d) the values are continuous i.e $p \in \lbrack 0,1 \rbrack $. \relax }{figure.caption.95}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Samples from the $28 \times 28$ pixel MNIST dataset \cite  {lecun-mnisthandwrittendigit-2010}. The pixel values $p$ are scales to be in the interval $p \in [0,1 ]$. \relax }}{58}{figure.caption.96}}
\newlabel{fig:mnist}{{6.2}{58}{Samples from the $28 \times 28$ pixel MNIST dataset \cite {lecun-mnisthandwrittendigit-2010}. The pixel values $p$ are scales to be in the interval $p \in \lbrack 0,1 \rbrack $. \relax }{figure.caption.96}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Visualization of samples from the Poker-DVS dataset \cite  {serrano2013128}. The images are generated by integrating all events over $8$ ms. The actual training is performed on the events.\relax }}{59}{figure.caption.97}}
\newlabel{fig:pokerdvs}{{6.3}{59}{Visualization of samples from the Poker-DVS dataset \cite {serrano2013128}. The images are generated by integrating all events over $8$ ms. The actual training is performed on the events.\relax }{figure.caption.97}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Computational Constrains}{59}{subsection.6.2.1}}
\newlabel{c:compconstr}{{6.2.1}{59}{Computational Constrains}{subsection.6.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Visualized filters $16 \times 16$ filters of the first layer convolutional RBM of a DBN trained on the $28 \times 28$ pixel MNIST dataset.\relax }}{60}{figure.caption.98}}
\newlabel{fig:rbmw}{{6.4}{60}{Visualized filters $16 \times 16$ filters of the first layer convolutional RBM of a DBN trained on the $28 \times 28$ pixel MNIST dataset.\relax }{figure.caption.98}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Conversion}{60}{subsection.6.2.2}}
\newlabel{c:conversionexp}{{6.2.2}{60}{Conversion}{subsection.6.2.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Kullback-Leibler divergence between the activations in the feature maps.\relax }}{61}{table.caption.100}}
\newlabel{tab:kldiv}{{6.1}{61}{Kullback-Leibler divergence between the activations in the feature maps.\relax }{table.caption.100}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces Classification performances of the converted spiking DBNs to a the artificial DBN on a subset of 100 samples.\relax }}{61}{table.caption.101}}
\newlabel{tab:convperf}{{6.2}{61}{Classification performances of the converted spiking DBNs to a the artificial DBN on a subset of 100 samples.\relax }{table.caption.101}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Conversion comparison}{61}{section*.99}}
\newlabel{c:conversioncomp}{{6.2.2}{61}{Conversion comparison}{section*.99}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 185}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub1}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 190}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 195}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 200}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 206}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub1}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 211}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 216}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 221}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 227}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub1}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 232}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 237}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 242}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 248}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub1}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 253}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 258}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub2}{{\caption@xref {fig:sub2}{ on input line 263}}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{}{62}{Conversion comparison}{figure.caption.102}{}}
\newlabel{fig:sub1}{{6.5a}{62}{artificial DBN.\relax }{figure.caption.102}{}}
\newlabel{sub@fig:sub1}{{a}{62}{artificial DBN.\relax }{figure.caption.102}{}}
\newlabel{fig:sub2}{{6.5b}{62}{spiking CNN.\relax }{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{b}{62}{spiking CNN.\relax }{figure.caption.102}{}}
\newlabel{fig:sub2}{{6.5c}{62}{COBA LIF DBN.\relax }{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{c}{62}{COBA LIF DBN.\relax }{figure.caption.102}{}}
\newlabel{fig:sub2}{{6.5d}{62}{CUBA LIF DBN.\relax }{figure.caption.102}{}}
\newlabel{sub@fig:sub2}{{d}{62}{CUBA LIF DBN.\relax }{figure.caption.102}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Activations in the features maps in a artificial convolutional DBN and the converted spiking network architectures. \relax }}{62}{figure.caption.102}}
\newlabel{fig:convacts}{{6.5}{62}{Activations in the features maps in a artificial convolutional DBN and the converted spiking network architectures. \relax }{figure.caption.102}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Classification performances of the converted spiking DBNs with different simulated runtimes.\relax }}{62}{table.caption.104}}
\newlabel{tab:pervovert}{{6.3}{62}{Classification performances of the converted spiking DBNs with different simulated runtimes.\relax }{table.caption.104}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 300}}{63}{Conversion comparison}{figure.caption.103}{}}
\newlabel{sub@fig:sub1}{{}{63}{Conversion comparison}{figure.caption.103}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 305}}{63}{Conversion comparison}{figure.caption.103}{}}
\newlabel{sub@fig:sub1}{{}{63}{Conversion comparison}{figure.caption.103}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 310}}{63}{Conversion comparison}{figure.caption.103}{}}
\newlabel{sub@fig:sub1}{{}{63}{Conversion comparison}{figure.caption.103}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 315}}{63}{Conversion comparison}{figure.caption.103}{}}
\newlabel{sub@fig:sub1}{{}{63}{Conversion comparison}{figure.caption.103}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Misclassifications of the spiking DBNs. Often $9$ and $4$ are mixed up. The first three are classified as a $9$, the fourth one is classified as a $4$. The images all share a lot of features with the suggested class and the correct class was always the second most probable.\relax }}{63}{figure.caption.103}}
\newlabel{fig:mismnisthum}{{6.6}{63}{Misclassifications of the spiking DBNs. Often $9$ and $4$ are mixed up. The first three are classified as a $9$, the fourth one is classified as a $4$. The images all share a lot of features with the suggested class and the correct class was always the second most probable.\relax }{figure.caption.103}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.4}{\ignorespaces eCD-parameters for the experiments\relax }}{63}{table.caption.105}}
\newlabel{tab:ecdrunparam}{{6.4}{63}{eCD-parameters for the experiments\relax }{table.caption.105}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}eCD}{63}{subsection.6.2.3}}
\newlabel{c:ecdexp}{{6.2.3}{63}{eCD}{subsection.6.2.3}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 524}}{63}{eCD}{figure.caption.106}{}}
\newlabel{sub@fig:sub1}{{}{63}{eCD}{figure.caption.106}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 529}}{63}{eCD}{figure.caption.106}{}}
\newlabel{sub@fig:sub1}{{}{63}{eCD}{figure.caption.106}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 534}}{63}{eCD}{figure.caption.106}{}}
\newlabel{sub@fig:sub1}{{}{63}{eCD}{figure.caption.106}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 539}}{63}{eCD}{figure.caption.106}{}}
\newlabel{sub@fig:sub1}{{}{63}{eCD}{figure.caption.106}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 544}}{63}{eCD}{figure.caption.106}{}}
\newlabel{sub@fig:sub1}{{}{63}{eCD}{figure.caption.106}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 550}}{63}{eCD}{figure.caption.106}{}}
\newlabel{sub@fig:sub1}{{}{63}{eCD}{figure.caption.106}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 555}}{63}{eCD}{figure.caption.106}{}}
\newlabel{sub@fig:sub1}{{}{63}{eCD}{figure.caption.106}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 560}}{63}{eCD}{figure.caption.106}{}}
\newlabel{sub@fig:sub1}{{}{63}{eCD}{figure.caption.106}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 565}}{63}{eCD}{figure.caption.106}{}}
\newlabel{sub@fig:sub1}{{}{63}{eCD}{figure.caption.106}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Positive phase and negative phase of a diagonal stripe with 4 filters. In the first 4 images sets a stripe is learned, while during the last 4 images the model distribution is unlearned.\relax }}{63}{figure.caption.106}}
\newlabel{fig:ecdstrlearn}{{6.7}{63}{Positive phase and negative phase of a diagonal stripe with 4 filters. In the first 4 images sets a stripe is learned, while during the last 4 images the model distribution is unlearned.\relax }{figure.caption.106}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces Accumulated weight change for each training sample. As more samples are presented and the weights specialize, the total weight updates decrease.\relax }}{64}{figure.caption.107}}
\newlabel{fig:ecdwdiff}{{6.8}{64}{Accumulated weight change for each training sample. As more samples are presented and the weights specialize, the total weight updates decrease.\relax }{figure.caption.107}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Learning the data distribution}{64}{section*.108}}
\newlabel{c:datadistexp}{{6.2.3}{64}{Learning the data distribution}{section*.108}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 592}}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{sub@fig:sub1}{{}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 597}}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{sub@fig:sub1}{{}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 602}}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{sub@fig:sub1}{{}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 607}}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{sub@fig:sub1}{{}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 614}}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{sub@fig:sub1}{{}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 619}}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{sub@fig:sub1}{{}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 624}}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{sub@fig:sub1}{{}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 629}}{64}{Learning the data distribution}{figure.caption.109}{}}
\newlabel{sub@fig:sub1}{{}{64}{Learning the data distribution}{figure.caption.109}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces Visualization of the spikes in the visible layer during the positive phase and negative phase of a diagonal stripe. In the first column, at the beginning of the training, in the negative phase the network is not able to reconstruct the data distribution. As the training progresses (in the second and third column), the reconstruction approximates the original data sample more closely and is in the last column nearly perfect.\relax }}{64}{figure.caption.109}}
\newlabel{fig:posnegstrec}{{6.9}{64}{Visualization of the spikes in the visible layer during the positive phase and negative phase of a diagonal stripe. In the first column, at the beginning of the training, in the negative phase the network is not able to reconstruct the data distribution. As the training progresses (in the second and third column), the reconstruction approximates the original data sample more closely and is in the last column nearly perfect.\relax }{figure.caption.109}{}}
\newlabel{fig:sub1}{{6.10a}{65}{Spikes at the beginning.\relax }{figure.caption.110}{}}
\newlabel{sub@fig:sub1}{{a}{65}{Spikes at the beginning.\relax }{figure.caption.110}{}}
\newlabel{fig:sub2}{{6.10b}{65}{Spikes after some training.\relax }{figure.caption.110}{}}
\newlabel{sub@fig:sub2}{{b}{65}{Spikes after some training.\relax }{figure.caption.110}{}}
\newlabel{fig:sub2}{{6.10c}{65}{Total number of spikes per sample over time.\relax }{figure.caption.110}{}}
\newlabel{sub@fig:sub2}{{c}{65}{Total number of spikes per sample over time.\relax }{figure.caption.110}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces Spikes in the hidden layer of a spiking convolutional RBM. At the start of the training (a) is appears mostly random, while after training the activations become more sparse ((b) and (c)) and certain neurons become specialized on certain input patterns (b).\relax }}{65}{figure.caption.110}}
\newlabel{fig:actdevstr}{{6.10}{65}{Spikes in the hidden layer of a spiking convolutional RBM. At the start of the training (a) is appears mostly random, while after training the activations become more sparse ((b) and (c)) and certain neurons become specialized on certain input patterns (b).\relax }{figure.caption.110}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Lateral connections}{65}{section*.111}}
\newlabel{c:latinhibexp}{{6.2.3}{65}{Lateral connections}{section*.111}{}}
\newlabel{fig:sub1}{{6.11a}{65}{\relax }{figure.caption.112}{}}
\newlabel{sub@fig:sub1}{{a}{65}{\relax }{figure.caption.112}{}}
\newlabel{fig:sub2}{{6.11b}{65}{\relax }{figure.caption.112}{}}
\newlabel{sub@fig:sub2}{{b}{65}{\relax }{figure.caption.112}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces $5 \times 5$ convolution filter matrices with and without lateral inhibitory connections in the top RBM layer on the stripe dataset. In (a) the weight are trained without lateral inhibitory connections and in (b) they are trained with lateral inhibitory connections. Whereas the filters without lateral connections (a) look more similar the filters with lateral connections (b) are more different and discriminative. \relax }}{65}{figure.caption.112}}
\newlabel{fig:latconstr}{{6.11}{65}{$5 \times 5$ convolution filter matrices with and without lateral inhibitory connections in the top RBM layer on the stripe dataset. In (a) the weight are trained without lateral inhibitory connections and in (b) they are trained with lateral inhibitory connections. Whereas the filters without lateral connections (a) look more similar the filters with lateral connections (b) are more different and discriminative. \relax }{figure.caption.112}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Convolution vs no Convolution}{66}{section*.113}}
\newlabel{c:convvsnoconvexp}{{6.2.3}{66}{Convolution vs no Convolution}{section*.113}{}}
\newlabel{fig:sub1}{{6.12a}{66}{Weights of the DBN with convolutions.\relax }{figure.caption.114}{}}
\newlabel{sub@fig:sub1}{{a}{66}{Weights of the DBN with convolutions.\relax }{figure.caption.114}{}}
\newlabel{fig:sub2}{{6.12b}{66}{Weights of the DBN without convolutions.\relax }{figure.caption.114}{}}
\newlabel{sub@fig:sub2}{{b}{66}{Weights of the DBN without convolutions.\relax }{figure.caption.114}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces Weight of the first layers of the DBNs with and without convolutions with the same number of free parameters. In (a) are weights of the DBN with convolutions visualized and in (b) the weights of the DBN without convolutions.\relax }}{66}{figure.caption.114}}
\newlabel{fig:wwoconwconv}{{6.12}{66}{Weight of the first layers of the DBNs with and without convolutions with the same number of free parameters. In (a) are weights of the DBN with convolutions visualized and in (b) the weights of the DBN without convolutions.\relax }{figure.caption.114}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Simulation time}{66}{section*.115}}
\newlabel{c:simtimeexp}{{6.2.3}{66}{Simulation time}{section*.115}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.13}{\ignorespaces The runtime of a learning step in dependence on the size of the network. While the simulated time of $168$ms stays constant, the runtime increases linearly with the number of hidden units.\relax }}{67}{figure.caption.116}}
\newlabel{fig:simtime}{{6.13}{67}{The runtime of a learning step in dependence on the size of the network. While the simulated time of $168$ms stays constant, the runtime increases linearly with the number of hidden units.\relax }{figure.caption.116}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Performance on the stripe dataset}{67}{section*.117}}
\newlabel{c:stripeexp}{{6.2.3}{67}{Performance on the stripe dataset}{section*.117}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.14}{\ignorespaces Abstract architecture of the DBN for the stripe dataset.\relax }}{67}{figure.caption.118}}
\newlabel{fig:dbnstrarch}{{6.14}{67}{Abstract architecture of the DBN for the stripe dataset.\relax }{figure.caption.118}{}}
\newlabel{fig:sub1}{{6.15a}{68}{Weights a the beginning of training.\relax }{figure.caption.119}{}}
\newlabel{sub@fig:sub1}{{a}{68}{Weights a the beginning of training.\relax }{figure.caption.119}{}}
\newlabel{fig:sub2}{{6.15b}{68}{Weights after 250 samples.\relax }{figure.caption.119}{}}
\newlabel{sub@fig:sub2}{{b}{68}{Weights after 250 samples.\relax }{figure.caption.119}{}}
\newlabel{fig:sub2}{{6.15c}{68}{Weights after 500 samples.\relax }{figure.caption.119}{}}
\newlabel{sub@fig:sub2}{{c}{68}{Weights after 500 samples.\relax }{figure.caption.119}{}}
\newlabel{fig:sub2}{{6.15d}{68}{Weights after 750 samples.\relax }{figure.caption.119}{}}
\newlabel{sub@fig:sub2}{{d}{68}{Weights after 750 samples.\relax }{figure.caption.119}{}}
\newlabel{fig:sub2}{{6.15e}{68}{Weights after 1000 samples.\relax }{figure.caption.119}{}}
\newlabel{sub@fig:sub2}{{e}{68}{Weights after 1000 samples.\relax }{figure.caption.119}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.15}{\ignorespaces The development of the $5 \times 5$ convolution filter matrices in the first layer of a DBN during training with the convolutional eCD algorithm on $1000$ samples of the stripe dataset.\relax }}{68}{figure.caption.119}}
\newlabel{fig:stripesdbnw}{{6.15}{68}{The development of the $5 \times 5$ convolution filter matrices in the first layer of a DBN during training with the convolutional eCD algorithm on $1000$ samples of the stripe dataset.\relax }{figure.caption.119}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Performance on the Poker-DVS dataset}{68}{section*.122}}
\newlabel{c:pokerexp}{{6.2.3}{68}{Performance on the Poker-DVS dataset}{section*.122}{}}
\newlabel{fig:sub1}{{6.16a}{69}{Visible layer activations in the beginning.\relax }{figure.caption.120}{}}
\newlabel{sub@fig:sub1}{{a}{69}{Visible layer activations in the beginning.\relax }{figure.caption.120}{}}
\newlabel{fig:sub2}{{6.16b}{69}{Visible layer activations after 1000 samples.\relax }{figure.caption.120}{}}
\newlabel{sub@fig:sub2}{{b}{69}{Visible layer activations after 1000 samples.\relax }{figure.caption.120}{}}
\newlabel{fig:sub2}{{6.16c}{69}{Hidden layer activations in the beginning.\relax }{figure.caption.120}{}}
\newlabel{sub@fig:sub2}{{c}{69}{Hidden layer activations in the beginning.\relax }{figure.caption.120}{}}
\newlabel{fig:sub2}{{6.16d}{69}{Hidden layer activations after 1000 samples.\relax }{figure.caption.120}{}}
\newlabel{sub@fig:sub2}{{d}{69}{Hidden layer activations after 1000 samples.\relax }{figure.caption.120}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.16}{\ignorespaces Activations/ spikes in the layers of the first RBM during training. As the training progresses, the activations become more sparse. The hidden layer learns new representations for the data. The model distribution approximates the data distribution, resulting in a nearly perfect reconstruction of the input data.\relax }}{69}{figure.caption.120}}
\newlabel{fig:stripesspl1}{{6.16}{69}{Activations/ spikes in the layers of the first RBM during training. As the training progresses, the activations become more sparse. The hidden layer learns new representations for the data. The model distribution approximates the data distribution, resulting in a nearly perfect reconstruction of the input data.\relax }{figure.caption.120}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Conversion vs online}{69}{subsection.6.2.4}}
\newlabel{c:comparisonexp}{{6.2.4}{69}{Conversion vs online}{subsection.6.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Direct comparison}{69}{section*.128}}
\newlabel{fig:sub1}{{6.17a}{70}{Visible layer activations in the beginning.\relax }{figure.caption.121}{}}
\newlabel{sub@fig:sub1}{{a}{70}{Visible layer activations in the beginning.\relax }{figure.caption.121}{}}
\newlabel{fig:sub2}{{6.17b}{70}{Visible layer activations after 500 samples.\relax }{figure.caption.121}{}}
\newlabel{sub@fig:sub2}{{b}{70}{Visible layer activations after 500 samples.\relax }{figure.caption.121}{}}
\newlabel{fig:sub2}{{6.17c}{70}{Label layer activations in the beginning.\relax }{figure.caption.121}{}}
\newlabel{sub@fig:sub2}{{c}{70}{Label layer activations in the beginning.\relax }{figure.caption.121}{}}
\newlabel{fig:sub2}{{6.17d}{70}{Label layer activations after 500 samples.\relax }{figure.caption.121}{}}
\newlabel{sub@fig:sub2}{{d}{70}{Label layer activations after 500 samples.\relax }{figure.caption.121}{}}
\newlabel{fig:sub2}{{6.17e}{70}{Hidden layer activations in the beginning.\relax }{figure.caption.121}{}}
\newlabel{sub@fig:sub2}{{e}{70}{Hidden layer activations in the beginning.\relax }{figure.caption.121}{}}
\newlabel{fig:sub2}{{6.17f}{70}{Hidden layer activations after 500 samples.\relax }{figure.caption.121}{}}
\newlabel{sub@fig:sub2}{{f}{70}{Hidden layer activations after 500 samples.\relax }{figure.caption.121}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.17}{\ignorespaces Activations/ spikes in the layers of the second RBM during training. As the training progresses, the activations become more sparse. The hidden layer learns new 20 dimensional representations for the data. The model distribution approximates the data distribution, resulting in a nearly perfect reconstruction of the input data, especially of the label.\relax }}{70}{figure.caption.121}}
\newlabel{fig:stripesspl2}{{6.17}{70}{Activations/ spikes in the layers of the second RBM during training. As the training progresses, the activations become more sparse. The hidden layer learns new 20 dimensional representations for the data. The model distribution approximates the data distribution, resulting in a nearly perfect reconstruction of the input data, especially of the label.\relax }{figure.caption.121}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.18}{\ignorespaces Abstract architecture of the DBN for the poker dataset.\relax }}{71}{figure.caption.123}}
\newlabel{fig:pokerdbnarch}{{6.18}{71}{Abstract architecture of the DBN for the poker dataset.\relax }{figure.caption.123}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.19}{\ignorespaces Visualization of the convolution filters of the first layer RBM trained with the convolutional eCD algorithm on the Poker-DVS dataset.\relax }}{71}{figure.caption.124}}
\newlabel{fig:pokerw}{{6.19}{71}{Visualization of the convolution filters of the first layer RBM trained with the convolutional eCD algorithm on the Poker-DVS dataset.\relax }{figure.caption.124}{}}
\newlabel{fig:sub1}{{6.20a}{72}{Accuracy of the DBN during training with 200 samples.\relax }{figure.caption.125}{}}
\newlabel{sub@fig:sub1}{{a}{72}{Accuracy of the DBN during training with 200 samples.\relax }{figure.caption.125}{}}
\newlabel{fig:sub2}{{6.20b}{72}{Reconstruction error of the first layer of the DBN during training with 200 samples.\relax }{figure.caption.125}{}}
\newlabel{sub@fig:sub2}{{b}{72}{Reconstruction error of the first layer of the DBN during training with 200 samples.\relax }{figure.caption.125}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.20}{\ignorespaces The accuracy and reconstruction error of the DBN. The accuracy increases to a maximal value of $90 \%$ and the reconstruction error decreases, indicating discriminative features. \relax }}{72}{figure.caption.125}}
\newlabel{fig:poker_err}{{6.20}{72}{The accuracy and reconstruction error of the DBN. The accuracy increases to a maximal value of $90 \%$ and the reconstruction error decreases, indicating discriminative features. \relax }{figure.caption.125}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 923}}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{sub@fig:sub1}{{}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 928}}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{sub@fig:sub1}{{}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 933}}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{sub@fig:sub1}{{}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 938}}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{sub@fig:sub1}{{}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 945}}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{sub@fig:sub1}{{}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 950}}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{sub@fig:sub1}{{}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 955}}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{sub@fig:sub1}{{}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 960}}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\newlabel{sub@fig:sub1}{{}{72}{Performance on the Poker-DVS dataset}{figure.caption.126}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.21}{\ignorespaces Positive phase and negative phase in the first layer of the DBN of after training on the Poker-DVS dataset. The reconstruction of each class is nearly perfect indicating, the DBN has learned the basic structure of the data.\relax }}{72}{figure.caption.126}}
\newlabel{fig:pokerrecon}{{6.21}{72}{Positive phase and negative phase in the first layer of the DBN of after training on the Poker-DVS dataset. The reconstruction of each class is nearly perfect indicating, the DBN has learned the basic structure of the data.\relax }{figure.caption.126}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 973}}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{sub@fig:sub1}{{}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 978}}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{sub@fig:sub1}{{}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 983}}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{sub@fig:sub1}{{}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 988}}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{sub@fig:sub1}{{}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 995}}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{sub@fig:sub1}{{}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 1000}}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{sub@fig:sub1}{{}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 1005}}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{sub@fig:sub1}{{}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{fig:sub1}{{\caption@xref {fig:sub1}{ on input line 1010}}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\newlabel{sub@fig:sub1}{{}{73}{Performance on the Poker-DVS dataset}{figure.caption.127}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.22}{\ignorespaces Completion of partially fed input data. In the first two columns the bottom $4$ rows and in the last two columns the $7$ bottom rows in the image data were omitted. After training, the DBN was able to reconstruct some of the missing input data an complete the input data.\relax }}{73}{figure.caption.127}}
\newlabel{fig:pokercompl}{{6.22}{73}{Completion of partially fed input data. In the first two columns the bottom $4$ rows and in the last two columns the $7$ bottom rows in the image data were omitted. After training, the DBN was able to reconstruct some of the missing input data an complete the input data.\relax }{figure.caption.127}{}}
\newlabel{fig:sub1}{{6.23a}{73}{Weights of the artificial DBN.\relax }{figure.caption.129}{}}
\newlabel{sub@fig:sub1}{{a}{73}{Weights of the artificial DBN.\relax }{figure.caption.129}{}}
\newlabel{fig:sub2}{{6.23b}{73}{Weights of the spinking DBN.\relax }{figure.caption.129}{}}
\newlabel{sub@fig:sub2}{{b}{73}{Weights of the spinking DBN.\relax }{figure.caption.129}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.23}{\ignorespaces Convolutional filters of the first layers of the artificial and spiking convolutional DBNs after 100 training samples. The weights of the spiking DBN appear to be more discriminative.\relax }}{73}{figure.caption.129}}
\newlabel{fig:convvsnoconv}{{6.23}{73}{Convolutional filters of the first layers of the artificial and spiking convolutional DBNs after 100 training samples. The weights of the spiking DBN appear to be more discriminative.\relax }{figure.caption.129}{}}
\@setckpt{content/exp}{
\setcounter{page}{74}
\setcounter{equation}{0}
\setcounter{enumi}{5}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{6}
\setcounter{section}{2}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{23}
\setcounter{table}{4}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{NAT@ctr}{0}
\setcounter{parentequation}{0}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{2}
\setcounter{subtable}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{4}
\setcounter{ALG@line}{4}
\setcounter{ALG@rem}{4}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{Item}{27}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{42}
\setcounter{section@level}{3}
}
