\chapter{Related Work}
\section{Convolutional RBM}

The convolutional RBM was invented more or less at the same time by Bengio and Lee. 
In similarity to CNN it can be seen as the advancement of energy based model adapting to compositional data.
Describing images in terms of spatially local features needs fewer parameters, generalizes better, and offers re-usability as identical local features can be extracted from different locations of an image.
Modeled after CNNs, cRBM have shared weights and are not fully connected.


For propagating information up can be seen as the convolution/cross correlation with a filter matrix $W$ : 
\[
P(\textbf{h} | \textbf{v}) = \sigma((W * \textbf{v}) + \textbf{b}_{h}).
\]
The down propagation uses the flipped kernel $\tilde{W}$ :
\[
P(\textbf{v}| \textbf{h}) = \sigma((\tilde{W} * \textbf{h}) + b_v).
\]
Using the convolution operation, the energy of the network can thus be rewritten as
\[
E(\textbf{h} , \textbf{v}) = \textbf{h}^\intercal(W * \textbf{v}) + \textbf{h}^\intercal \textbf{b}_{h} + \sum b v_i.
\]

%\begin{figure}
%	\centering
%	\begin{subfigure}[t]{.30\textwidth}
%  		\centering
%  		\includegraphics[width=.8\linewidth]{imgs/crbm1.png}
%  		\caption{A subfigure}
%  		\label{fig:sub1}
%	\end{subfigure}%
%	\begin{subfigure}[t]{.30\textwidth}
%  		\centering
%  		\includegraphics[width=.8\linewidth]{imgs/kernel_flip.png}
%  		\caption{A subfigure}
%  		\label{fig:sub2}
%	\end{subfigure}
%	\begin{subfigure}[t]{.30\textwidth}
%  		\centering
%  		\includegraphics[width=.8\linewidth]{imgs/crbm2.png}
%  		\caption{A subfigure}
%  		\label{fig:sub3}
%	\end{subfigure}
%\end{figure}


\begin{figure}
	\centering
	\begin{subfigure}[t]{.30\textwidth}
  		\centering
  		\includegraphics[width=.8\linewidth]{imgs/crbm_padding1.png}
  		\caption{The upward pass in the convolutional RBM}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.30\textwidth}
  		\centering
  		\includegraphics[width=.8\linewidth]{imgs/kernel_flip.png}
  		\caption{The 180\textdegree  flipped of the kernel matrix}
  		\label{fig:sub2}
	\end{subfigure}
	\begin{subfigure}[t]{.30\textwidth}
  		\centering
  		\includegraphics[width=.8\linewidth]{imgs/crbm_padding2.png}
  		\caption{The downward pass in the convolutional RBM}
  		\label{fig:sub3}
	\end{subfigure}
	\caption{A Gibbs sampling step in a convolutional RBM. At first the visible data is convolved with the kernel to get the hidden activations. Afterwards the kernel matrix is flipped 180\textdegree . In the downward pass the hidden activations with padding are convolved with the flipped kernel to get the new visible activations.}
	\label{fig:convrbm}
\end{figure}


Learning is similar to normal a RBM, a convolutional RBM is trained with the objective to maximize the probability of the training data.
This can be achieved using the CD algorithm with a few adaptations due to the tied weights (see backprop for CNNs, $\frac{\partial E}{\partial w} = \sum \Delta w$).

In contrast to CNNs, due to their local learning rule, RBMs can not be explicitly trained to perform max pooling operations.
Thus Lee proposed an softmax based probabilistic max pooling to introduce local sparseness in the hidden activations, on which a pooling layer can be stacked:
\[
P(h^k_{ij} | \textbf{v}) = \frac{\exp(I(h^k_{ij}))}{1 + \sum_{(i',j') \in B} \exp(I(h^k_{i'j'}))},
\]
where $I(h^k_{ij})$ is the activation of the hidden unit before applying the sigmoid function ( $(W * \textbf{v}) + \textbf{b}_{h}$ ) and $B$ is a partition block containing unit $h^k_{ij}$. 

\begin{figure}
	\centering
    	\includegraphics[width=0.4\textwidth]{imgs/prob_max_pool.png} 
    \caption{The RBM layer architecture with probabilistic max pooling.}
	\label{fig:probmaxpool}
\end{figure}


\section{Sampling in SNNs}

Indicated by stochastic neural tranisitions found in the brain in experimental studdies, a new way of information encoding in the brain as representations of probability distributions and probabilistic interference has been suggested.


A first framework which proposed how spiking neurons can perform MCMC sampling was introduced by Buesing.
A simplification to discretize time in time slices can be introduced without interfering with the basic concept (see Buesing for the generalization to continuous time).

The neuron network can considered a network of RV, with the state of a neuron is defined by its firing. 
Since the probability of two neurons spiking at the same time is basically zero, after a neuron has fired it is set to the firing state for a time period $\tau$
\[
z_k(t) = 1 \iff k \text{ has fired in the time intervall } (t - \tau , t ] 
\] 
where $z_k$ is the state of neuron $k$ and set to $1$ for the "firing" state and $0$ for the "not firing" state. A common choice for $\tau$ is the refractory period of the neuron $\tau_{ref}$.
Consequently, one way to characterize the firing probability of a neuron is to take the ratio of the time a neuron has spent in state $z_i=1$ compared to the total timespan $T$ : $\frac{\#\text{spikes}_i \, \tau}{ T }$.

Thus for a given time step $t$ the state of the network $\textbf{z}(t) = (z_1(t), ... ,z_n(t))$ is defined by the state of the individual neurons $z_i(t)$. 


\begin{figure}
	\centering
    	\includegraphics[width=0.4\textwidth]{imgs/snn_sample1.png} 
    \caption{A spiking neural network as probabilistic model. The state $z_i$ of a neuron is set to $1$ for a time period $t_{on}$ after a spike. The complete state of the network $\textbf{z}$ is given by the individual state $(z_1, z_2, z_3, z_4)$ .}
	\label{fig:snnsamp1}
\end{figure}

To get a process with Markovian properties $p(z_t| (z_0, ..., z_{t-1})) = p(z_t| z_{t-1}) $, a auxiliary counter variable $\xi$ is introduced which discretizes the time a neuron has left to stay in the "firing" into time slices
\[
z_k(t) = 1 \iff \xi_k(t) \ge 1
\]
Thus $\xi$ can be seen as a counter, counting down from $\tau$ to $0$ in each time step after a neuron has fired
\[
p(\xi_t | \xi_{t-1}) = 
\begin{cases}
	1, & \text{ for } \xi_{t-1} > 1 \text{ and } \xi_t = \xi_{t-1} -1 ,\\
	p("firing"), & \text{ for } \xi_{t-1} \le 1 \text{ and } \xi_t = \tau ,\\
	p("not firing"), & \text{ for } \xi_{t-1} \le 1 \text{ and } \xi_t = 0 ,\\
	0, & \text{otherwise}.
\end{cases}
\]

\begin{figure}
	\centering
    	\includegraphics[width=0.4\textwidth]{imgs/snn_sample2.png} 
    \caption{The artificial counter state $\xi$ of a neuron in a discrete time. The red state represent an active state $z_i = 1$. After a spike $\xi$ is set to the refactory period $\tau$. In each time step the refractory period counter $\xi$ is reduced by 1 until the neuron is inactive and can spike again.}
	\label{fig:snnsamp2}
\end{figure}

Buesing proposes an abstract stochastic neuron model which activates with a probability proportional to the input
\[
P(\textit{"i fires at time t"}) \approx \sigma(\sum_j w_{ij} z_j(t) + b_i).
\]
With this model Buesing proved that spikes and the corresponding state updates in a such networks can be seen as MCMC sampling. Experiments show, as $t \rightarrow \infty$ , the network is in fact able to approximate a Boltzmann distribution.
Replacing the rectangular PSP with a more biolgical plausible alpha shaped PSP deteriorates the performance, due to overshooting at the beginning and accumulation effects, a little but is still reasonable well.

\begin{figure}
	\centering
	\begin{subfigure}[t]{.50\textwidth}
  		\centering
  		\includegraphics[width=.8\linewidth]{imgs/snn_sample3.png}
  		\caption{Sampling in a Boltzmann machine with a rectangular PSP kernel.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.50\textwidth}
  		\centering
  		\includegraphics[width=.8\linewidth]{imgs/snn_sample4.png}
  		\caption{Sampling in a Boltzmann machine with a alpha-shaped PSP kernel. }
  		\label{fig:sub2}
	\end{subfigure}
	\caption{Comparison of the state probabilities with of neural sampling with Gibbs sampling in a four state Boltzmann machine. In (a) a probabilistic neuron model with a rectangular PSP is used and no discrepancies can be detected given a long enough sampling period. In (b) a more biological plausible alpha shaped kernel is used, which leads to some differences.}
	\label{fig:snnsamp3}
\end{figure}

Petrovici improved the model by replacing the stochastic neuron model by conductance bases LIF neurons, a more common and biologically inspired neuron model.
He proved under high frequency (poisson) noise, which leads to a high conductance state of the membrane potential, the neuron shows stochastic firing, determined by the input current and the noise frequency.
This allows the neuron to show a firing behavior which can be matched by a logistic function.  
By normalizing the weights, the LIF neurons can so perform neural sampling similar to Buesing.

\begin{figure}
	\centering
    	\includegraphics[width=0.4\textwidth]{imgs/snn_sample5.png} 
    \caption{Input output transfer function of a neuron in a high conductance state. The output rate is normalized by $\frac{1}{\tau_{ref}}$ to get a output probability. The transfer function is identical to shifted sigmoid function $\sigma$.}
	\label{fig:snnsmap4}
\end{figure}

\section{Artificial to spiking neural network conversion}

The results of Petrovici allow a quite simple transformation of a Boltzmann machine to spiking neural networks of noisy conductance based LIF neurons with the synaptic weights scaled to match the impact on the membrane potential.
\\
\\
Connor uses a different approach, where he instead of approximating sigmoid units by LIF neurons, uses the Siegert neuron, a rate base approximations of LIF neurons with Poisson input, to implement units in the RBM which activate similary to LIF neurons. 
Such a trained net can be directly transfered to a SNN.
For a neuron with input rates $\rho$ and weights $w$ the output rate can be approximated by the Siegert transformation as
\[
\rho_{out} = \bigg(t_{ref} + \frac{\tau}{\Gamma} \sqrt{\frac{\pi}{2}} \int_{V_{reset}+k\gamma\Gamma}^{V_{thres}+k\gamma\Gamma} \exp \Big[ \frac{(u - \Upsilon)^2}{2 \Gamma^2} \Big] \Big[ 1 + \text{erf} \Big( \frac{u - \Upsilon}{\Gamma \sqrt{2}} \Big) \Big] du \bigg)^{-1},
\] 
with the auxiliary variables
\[
\begin{split}
	\mu_Q = \tau \sum w \rho ,\\
	\sigma_Q^2 = \frac{\tau}{2} \sum w^2 \rho,\\
	\Upsilon = V_{rest} + \mu_Q ,\\
	\Gamma = \sigma_Q ,\\
	k = \sqrt{\frac{\tau_{syn}}{\tau}},\\
	\gamma = |\xi(\frac{1}{2})|,\\
\end{split},
\]
where $\xi$ is the Riemann zeta function.

$\rho_{out}$ can be normalized by the maximal firing rate $\frac{1}{\tau_{ref}}$ to get an activation probability, which can be adapted by the units of the RBM. 
After the RBM with the Siegert activation function is trained, the weight can be simply adapted to a SNN with LIF neurons described by the Siegert approximation.
\\
\\
There also have been several approaches to transform a CNN to a SNN.  
Cao et al and Diehl et al propose certain constrains on the CNN architecture to show reasonable performance in the converted SNN:
\begin{itemize}
\item The CNN is only fed positive data since SNNs can't represent negative pre-synaptic spikes. 
\item The ReLU activation function is used in the CNN, which closely matches the input-output mapping of LIF neurons without a refractory period $t_{ref}$ .
\item The bias term are eliminated.
\item Instead of max pooling, average pooling is used, since it has a simple spiking counterpart.
\end{itemize}
After the CNN is trained with the back propagation algorithm, the weights are transferred to a SNN with an equivalent architecture using LIF neurons without a refractory period. 
In addition Diehl et al use some model- and data-based weight normalization procedure to further fine-tune the synaptic weights. 

\begin{figure}
	\centering
	\begin{subfigure}[t]{.50\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/cnn_snn_conv1.jpg}
  		\caption{A for conversion adapted CNN architecture.}
  		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}[t]{.50\textwidth}
  		\centering
  		\includegraphics[width=.9\linewidth]{imgs/cnn_snn_conv2.jpg}
  		\caption{A to an SNN converted convolutional network.}
  		\label{fig:sub2}
	\end{subfigure}
	\caption{The proposed architectures to conversion between CNNs and SNNs. }
\end{figure}

\section{eCD and Sampling Machines}

Different approaches have been proposed to train a rate based RBM, where the first was probably by Hinton.
They use multiple binary stochastic input units of the same input to simulate a rate based input.

The next approaches make use of the synaptic sampling described in the previous chapter.

One approach is the evtCD by Daniel Neil which works in continuous time with spiking networks and a STDP variant.
He simulates the positive and negative phase of the CD by simply unrolling the RBM (with shared weights). 
But this approach only allows a certain number of CD steps and is due to the weight synchronization not very plausible.

\begin{figure}
	\centering
    	\includegraphics[width=0.4\textwidth]{imgs/evtCD.png} 
    \caption{An unrolled RBM with tied weights, which can be used to simulate the positive and negative phase and learn the weighs online.}
	\label{fig:evtCD}
\end{figure}

A more sophisticated approach which also uses STDP was proposed by Neftci.
He uses bidirectional synapses, between a visible and hidden layer of LIF neurons.
They use an adapted symmetric STDP variant, which at a given time only allows LTP or LDP to model the positive or negative phase of the CD algorithm respectively. 
The symmetric learning rule for two neurons, given their spike train $v_i(t)$ and $h_j(t)$, can be expressed as:
\[
\Delta w_{ij} = \mu g(t) STDP(v_i(t), h_j(t)),
\]
with the learning rule $\mu$, the STDP status flag $g(t)$ determining the positive and negative phase of the CD algorithm and the STDP function $STDP(v, h)$ determining the weight change depended in the neural activity:
\[
\begin{split}
STDP(v_i(t), h_j(t)) = v_i(t) A_{h_j}(t) + h_j(t) A_{v_i}(t), \\
A_{h_j}(t) = A \int_{- \infty}^t W(t-s) h_j(s) ds, \\ 
A_{v_i}(t) = A \int_{- \infty}^t W(t-s) v_i(s) ds. \\ 
\end{split}
\]
In this STDP rule $A(t)$ can be seen as an activity trace indicating recent behaviour and $v_i(t)$ , $h_j(t)$ as a control variable enabling weight changes given a spike at time $t$.    
The kernel function $W$ should be symmetric, a common choice is $W(x) = exp(\frac{x}{\tau})$. 

\begin{figure}
	\centering
    	\includegraphics[width=0.8\textwidth]{imgs/eCD2.png} 
    \caption{Comparison between classical CD and event-based CD. In the classical k-CD (a) the weight update is determined by positive phase and negative phase, while in event-base CD (b) the weight update is determined by STDP and the sampling phase, determined by $g$.}
	\label{fig:test}
\end{figure}
  
In their approach the training time can be divided into four phases:
\begin{enumerate}
\item The data signal is applied and the system is allowed to model the data distribution ($g(t)=0$)
\item Positive STDP is used to get $v_i h_j$-data (with stdp) and is added to the weights (postive phase $g(t)=1$)
\item The data signal is remove and the system is allowed to model the model distribution ($g(t)=0$)
\item Negative STDP is used to get $v_i h_j$-model (with stdp) and is substracted from the synaptic weights (negative phase $g(t)=-1$).
\end{enumerate}


\begin{figure}
	\centering
    	\includegraphics[width=0.3\textwidth]{imgs/eCD11.png} 
    \caption{Visualization of the phases of the event based contrastive divergence.}
	\label{fig:test}
\end{figure}

In similarity to RBMs, the weight change in the second phase can be summarized as $\mu \; \delta w_{pos}$, the weight change in the fourth phase as $\mu \; \delta w_{neg}$, which results in the CD update rule:
\[
w = w +  \mu \; \delta w_{pos} - \mu \; \delta w_{neg} = w +  \mu (\delta w_{pos} - \delta w_{neg}).
\]
 